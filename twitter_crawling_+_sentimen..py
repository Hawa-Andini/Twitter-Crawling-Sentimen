# -*- coding: utf-8 -*-
"""Twitter Crawling + Sentimen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ABbEG-ohb2TsfzxG6K9GOziEXE9zVJDp
"""

#@title Twitter Auth Token

twitter_auth_token = 'e0894f47e0b585cdec33c696326c672c5dcce3dd' # change this auth token

# Import required Python package
!pip install pandas

# Install Node.js (because tweet-harvest built using Node.js)
!sudo apt-get update
!sudo apt-get install -y ca-certificates curl gnupg
!sudo mkdir -p /etc/apt/keyrings
!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg

!NODE_MAJOR=20 && echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | sudo tee /etc/apt/sources.list.d/nodesource.list

!sudo apt-get update
!sudo apt-get install nodejs -y

!node -v

# Crawl Data

filename = 'fomo.csv'
search_keyword = 'fomo since:2024-04-01 until:2025-04-01 lang:id'
limit = 100

!npx -y tweet-harvest@2.6.1 -o "{filename}" -s "{search_keyword}" --tab "LATEST" -l {limit} --token {twitter_auth_token}

import pandas as pd

# Specify the path to your CSV file
file_path = f"tweets-data/{filename}"

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_path, delimiter=",")

# Display the DataFrame
display(df)

# Cek jumlah data yang didapatkan

num_tweets = len(df)
print(f"Jumlah tweet dalam dataframe adalah {num_tweets}.")

df

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# Load the tokenizer and model
model_name = "w11wo/indonesian-roberta-base-sentiment-classifier"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Create a pipeline
sentiment = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# Run sentiment analysis
text = "Ih gemeees aku fomo tapi gak paham mainnya "
result = sentiment(text)

print(result)

results = []
for i in df['full_text']:
  results.append(sentiment(i))
  print(i)

results

# Proses analisis sentimen
results = []
for i in df['full_text']:
    try:
        result = sentiment(i)[0]['label']
    except:
        result = 'error'
    results.append(result)

# Tambahkan kolom sentimen
df['sentiment'] = results

# Tampilkan tabel seperti di gambar
df[['full_text', 'sentiment']].head()

import seaborn as sns
import matplotlib.pyplot as plt

# --- Bar Chart ---
plt.figure(figsize=(6, 4))
sns.countplot(
    x='sentiment',
    data=df,
    order=df['sentiment'].value_counts().index,
    palette='Set2'
)
plt.title('Distribusi Sentimen (Bar Chart)')
plt.xlabel('Sentimen')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- Pie Chart ---
plt.figure(figsize=(6, 6))
df['sentiment'].value_counts().plot.pie(
    autopct='%1.1f%%',
    startangle=140,
    colors=sns.color_palette('Set2'),
    shadow=True,
    explode=[0.05]*df['sentiment'].nunique()
)
plt.title('Distribusi Sentimen (Pie Chart)')
plt.ylabel('')
plt.tight_layout()
plt.show()